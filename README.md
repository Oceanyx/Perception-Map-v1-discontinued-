# Perception Map â€” Version 1 (Discontinued)

This was my first attempt at making a tool for mapping perception.
V1 helped me figure out what the project actually *was*, but the structure didnâ€™t hold up, so Iâ€™m documenting it here before moving on to V2.

---

## ğŸ¯ What V1 Tried to Do

The idea:

When you notice a perception happening â€” a reaction, a thought, a shift â€” you could break it down into three categories:

* **Private** â€” internal sensations, emotions
* **Public** â€” behaviors, interactions
* **Abstract** â€” interpretations, frameworks, concepts

The UI was a big canvas with three circles.
You dragged nodes into whichever circle fit, and connected them if they related.

It workedâ€¦ kind of. But the structure ended up being too rigid for how perception actually flows.

---

## ğŸ§© What Nodes Contained

Each node stored:

* plain text (the content)
* a domain (based on circle placement)
* an optional lens (e.g., â€œpsychological,â€ â€œrelationalâ€)
* an optional interpretation or reflection

Simple, but very manual.

---

## ğŸ›‘ Why I Ultimately Stopped Working on V1

### 1. The spatial layout became confusing

Perception isnâ€™t literally spatial, but the UI forced it to be.

### 2. It took too much mental effort

You had to think about *how* to map before mapping anything.

### 3. It pushed interpretation too early

Some perceptions just need to be noticed â€” not analyzed right away.

### 4. No way to see patterns across multiple moments

Everything stayed inside one canvas. No â€œbigger picture.â€

### 5. Architecture couldnâ€™t scale

One playground = one moment, with no system for organizing or saving instances.

All of that led to starting V2 from scratch instead of patching V1.

---

## ğŸ¥ Video Overview (Placeholder)

> **[Add Video Here]**
> Iâ€™ll include a walkthrough explaining what worked, what didnâ€™t, and why I rebuilt everything.

---

## ğŸ” What I Learned (and What Shaped V2)

* Domains should be tags, not physical zones.
* Not every node needs a lens or interpretation.
* The UI should *never* pressure insight.
* Insights come from linking across instances, not over-processing one.
* Flexibility beats structure every time.

---

## ğŸ“¦ Project Status

* **V1:** Archived â€” used for reference only
* **V2:** Being redesigned from the ground up
* **This repo:** Documentation + starter scaffold

---

# ğŸ§ª Perception Map â€” Starter Scaffold

This repo includes a minimal setup so the playground can run.

---

## ğŸ›  How to Run

1. `npm install`
2. `npm run dev`

Tech stack:

* âš¡ **Vite**
* âš›ï¸ **React**
* ğŸ¨ **Tailwind**
* ğŸ§­ **React Flow**
* ğŸ’¾ **Dexie** (local IndexedDB)

---

## âœï¸ Notes

This starter is intentionally barebones.
You can expand `CanvasView` however you want:

* add lens visuals
* add domain overlays
* build link/connection logic
* create a proper node editing panel
* experiment with UI layouts

Itâ€™s just the starting point â€” not the full tool.
